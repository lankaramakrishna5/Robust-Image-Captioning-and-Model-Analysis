{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11404048,"sourceType":"datasetVersion","datasetId":7143090}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- Part C: Imports and Constants ---\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    BertTokenizer,\n    BertForSequenceClassification, # Using this simplifies the model definition\n    get_linear_schedule_with_warmup # Optional: for learning rate scheduling\n)\nfrom tqdm.auto import tqdm # Use tqdm.auto for notebook compatibility\n\n\n# --- Constants ---\n# Ensure these are defined in your first cell\nPART_C_INPUT_CSV = \"/kaggle/input/kakaka/part_c_train.csv\" # <--- SET THIS PATH\nINPUT_TEXT_COL_NAME = 'input_text' # The actual name of the input text column\nLABEL_COL_NAME = 'output_label' # The actual name of the label column\nVALIDATION_SIZE = 0.10\nTEST_SIZE = 0.20\nRANDOM_SEED = 42\n\n\n\nBERT_MODEL_NAME = \"google-bert/bert-base-uncased\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Hyperparameters (can be adjusted later)\nMAX_LEN = 128       # Max sequence length for BERT tokenizer\nBATCH_SIZE = 16     # Adjust based on GPU memory\nEPOCHS = 4          # Number of training epochs\nLEARNING_RATE = 2e-5 # Common learning rate for BERT fine-tuning\n\n# Data split ratios\nTEST_SIZE = 0.20    # 20% for test set\nVALIDATION_SIZE = 0.10 # 10% for validation set (taken from the initial 80%)\n\n# Random state for reproducibility\nRANDOM_SEED = 42\n\n# Label mapping\nLABEL_MAP = {'SmolVLM': 0, 'Custom': 1} # Map model type strings to integers\n\nprint(f\"Using device: {DEVICE}\")\nprint(f\"BERT Model: {BERT_MODEL_NAME}\")\nif os.path.exists(PART_B_CSV_PATH):\n    print(f\"Input Data CSV: {PART_B_CSV_PATH}\")\nelse:\n    print(f\"WARNING: Input CSV not found at {PART_B_CSV_PATH}. Data loading will fail.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:28.619714Z","iopub.execute_input":"2025-04-14T14:53:28.620251Z","iopub.status.idle":"2025-04-14T14:53:28.628295Z","shell.execute_reply.started":"2025-04-14T14:53:28.620224Z","shell.execute_reply":"2025-04-14T14:53:28.627561Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nBERT Model: google-bert/bert-base-uncased\nInput Data CSV: /kaggle/input/kakaka/part_c_train.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- Part C: Load Data and Split (RANDOM ROW SPLIT ) ---\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\n\n\nprint(f\"\\nLoading pre-formatted data from: {PART_C_INPUT_CSV}\")\nprint(\"WARNING: Performing RANDOM ROW SPLIT, not image-based split.\")\n\ntry:\n    df = pd.read_csv(PART_C_INPUT_CSV)\n    print(f\"Loaded data. Shape: {df.shape}\")\nexcept FileNotFoundError:\n    print(f\"ERROR: Input CSV not found at {PART_C_INPUT_CSV}\")\n    df = pd.DataFrame()\nexcept Exception as e:\n    print(f\"Error loading CSV: {e}\")\n    df = pd.DataFrame()\n\n# --- Basic Data Cleaning ---\nif not df.empty:\n    print(\"\\nCleaning data...\")\n    required_cols = [INPUT_TEXT_COL_NAME, LABEL_COL_NAME]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns in CSV: {missing_cols}\")\n\n    initial_rows = len(df)\n    df.dropna(subset=[INPUT_TEXT_COL_NAME, LABEL_COL_NAME], inplace=True)\n    df = df[df[INPUT_TEXT_COL_NAME].astype(str).str.strip().str.len() > 0]\n    df[LABEL_COL_NAME] = pd.to_numeric(df[LABEL_COL_NAME], errors='coerce')\n    df.dropna(subset=[LABEL_COL_NAME], inplace=True)\n    df[LABEL_COL_NAME] = df[LABEL_COL_NAME].astype(int)\n    cleaned_rows = len(df)\n    print(f\"Rows before cleaning: {initial_rows}, Rows after cleaning: {cleaned_rows}\")\n    if cleaned_rows == 0:\n        print(\"ERROR: Dataframe is empty after cleaning.\")\n\n# --- Random Row-Based Train/Validation/Test Split ---\ndf_train, df_val, df_test = pd.DataFrame(), pd.DataFrame(), pd.DataFrame() # Initialize\n\nif not df.empty:\n    print(\"\\nPerforming random row-based Train/Val/Test split...\")\n    # Split into Train and Temp (Val + Test)\n    df_train, df_temp = train_test_split(\n        df,\n        test_size=(VALIDATION_SIZE + TEST_SIZE),\n        random_state=RANDOM_SEED,\n        stratify=df[LABEL_COL_NAME] if df[LABEL_COL_NAME].nunique() > 1 else None # Stratify if possible\n    )\n\n    # Split Temp into Val and Test\n    if not df_temp.empty:\n        val_test_total = VALIDATION_SIZE + TEST_SIZE\n        relative_test_size = TEST_SIZE / val_test_total if val_test_total > 0 else 0.0\n        df_val, df_test = train_test_split(\n            df_temp,\n            test_size=relative_test_size,\n            random_state=RANDOM_SEED,\n            stratify=df_temp[LABEL_COL_NAME] if df_temp[LABEL_COL_NAME].nunique() > 1 else None # Stratify if possible\n        )\n    else:\n        df_val, df_test = pd.DataFrame(), pd.DataFrame()\n\n\n    # Rename columns for consistency with Dataset class\n    df_train = df_train.rename(columns={INPUT_TEXT_COL_NAME: 'input_text', LABEL_COL_NAME: 'label'})\n    df_val = df_val.rename(columns={INPUT_TEXT_COL_NAME: 'input_text', LABEL_COL_NAME: 'label'})\n    df_test = df_test.rename(columns={INPUT_TEXT_COL_NAME: 'input_text', LABEL_COL_NAME: 'label'})\n\n    print(f\"Data split complete:\")\n    print(f\"  Train set rows: {len(df_train)}\")\n    print(f\"  Validation set rows: {len(df_val)}\")\n    print(f\"  Test set rows: {len(df_test)}\")\n\n    # --- Check Test Set Label Distribution ---\n    if not df_test.empty:\n        print(\"\\n--- Test Set Label Distribution ---\")\n        print(df_test['label'].value_counts())\n        num_unique_labels_test = df_test['label'].nunique()\n        print(f\"Number of unique labels in test set: {num_unique_labels_test}\")\n        if num_unique_labels_test < 2:\n             print(\"\\nWARNING: Test set contains samples from only ONE class after random split.\")\n        else:\n            print(\"Test set contains samples from both classes.\")\n    else:\n        print(\"\\nWarning: Cannot check test set label distribution (df_test is empty).\")\n\n\nelse:\n    print(\"Skipping split as DataFrame is empty.\")\n\nprint(\"\\nData ready for Dataset creation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:28.631387Z","iopub.execute_input":"2025-04-14T14:53:28.631936Z","iopub.status.idle":"2025-04-14T14:53:28.774655Z","shell.execute_reply.started":"2025-04-14T14:53:28.631909Z","shell.execute_reply":"2025-04-14T14:53:28.773891Z"}},"outputs":[{"name":"stdout","text":"\nLoading pre-formatted data from: /kaggle/input/kakaka/part_c_train.csv\nWARNING: Performing RANDOM ROW SPLIT, not image-based split.\nLoaded data. Shape: (10624, 2)\n\nCleaning data...\nRows before cleaning: 10624, Rows after cleaning: 10624\n\nPerforming random row-based Train/Val/Test split...\nData split complete:\n  Train set rows: 7436\n  Validation set rows: 1062\n  Test set rows: 2126\n\n--- Test Set Label Distribution ---\nlabel\n1    1063\n0    1063\nName: count, dtype: int64\nNumber of unique labels in test set: 2\nTest set contains samples from both classes.\n\nData ready for Dataset creation.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Part C: PyTorch Dataset ---\n\n# Ensure BertTokenizer is imported\nfrom transformers import BertTokenizer\nimport torch\nfrom torch.utils.data import Dataset\n\nclass CaptionClassificationDataset(Dataset):\n    \"\"\"\n    PyTorch Dataset for the caption classification task.\n    Takes a DataFrame containing 'input_text' and 'label' columns.\n    Tokenizes the text using a BERT tokenizer.\n    \"\"\"\n    def __init__(self, dataframe, tokenizer, max_len):\n        \"\"\"\n        Args:\n            dataframe (pd.DataFrame): DataFrame for the split (train, val, or test)\n                                      containing 'input_text' and 'label' columns.\n            tokenizer (BertTokenizer): Initialized BERT tokenizer.\n            max_len (int): Maximum sequence length for tokenization.\n        \"\"\"\n        # Ensure required columns exist\n        if 'input_text' not in dataframe.columns or 'label' not in dataframe.columns:\n             raise ValueError(\"DataFrame must contain 'input_text' and 'label' columns.\")\n\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.input_text = dataframe.input_text.to_numpy() # Convert to numpy for faster access\n        self.labels = dataframe.label.to_numpy()\n        self.max_len = max_len\n\n    def __len__(self):\n        \"\"\"Returns the number of samples in the dataset.\"\"\"\n        return len(self.input_text)\n\n    def __getitem__(self, index):\n        \"\"\"\n        Retrieves a sample, tokenizes it, and returns tensors.\n        \"\"\"\n        text = str(self.input_text[index]) # Get the formatted input text\n        label = int(self.labels[index])    # Get the corresponding integer label\n\n        # Tokenize the input text\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,    # Add '[CLS]' and '[SEP]'\n            max_length=self.max_len,    # Pad or truncate to max_len\n            padding='max_length',       # Pad sequences to max_len\n            truncation=True,            # Truncate sequences longer than max_len\n            return_attention_mask=True, # Return attention mask\n            return_token_type_ids=False,# Not typically needed for single sequence/pair classification with BERT structure used here\n            return_tensors='pt',        # Return PyTorch tensors\n        )\n\n        # Return dictionary matching common input names for BERT models\n        return {\n            'input_text': text, # Keep original text for potential debugging\n            'input_ids': encoding['input_ids'].flatten(), # Remove the batch dimension (1, max_len) -> (max_len)\n            'attention_mask': encoding['attention_mask'].flatten(), # Remove the batch dimension\n            'labels': torch.tensor(label, dtype=torch.long) # Target label as a tensor\n        }\n\n# --- Initialize Tokenizer ---\n# Ensure BERT_MODEL_NAME is defined from the first snippet\nif 'BERT_MODEL_NAME' not in globals(): raise NameError(\"BERT_MODEL_NAME not defined.\")\nprint(f\"\\nInitializing BERT tokenizer: {BERT_MODEL_NAME}\")\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\nprint(\"Tokenizer initialized.\")\n\n\n# --- Create Datasets ---\n# Ensure df_train, df_val, df_test exist from the previous step\n# Ensure MAX_LEN is defined\nif 'MAX_LEN' not in globals(): raise NameError(\"MAX_LEN not defined.\")\n\ntrain_dataset = None\nval_dataset = None\ntest_dataset = None\n\nif 'df_train' in globals() and not df_train.empty:\n    print(\"\\nCreating Train Dataset...\")\n    train_dataset = CaptionClassificationDataset(\n        dataframe=df_train,\n        tokenizer=tokenizer,\n        max_len=MAX_LEN\n    )\n    print(f\"Train Dataset created with {len(train_dataset)} samples.\")\nelse:\n    print(\"Skipping Train Dataset creation (df_train is empty or undefined).\")\n\nif 'df_val' in globals() and not df_val.empty:\n    print(\"\\nCreating Validation Dataset...\")\n    val_dataset = CaptionClassificationDataset(\n        dataframe=df_val,\n        tokenizer=tokenizer,\n        max_len=MAX_LEN\n    )\n    print(f\"Validation Dataset created with {len(val_dataset)} samples.\")\nelse:\n    print(\"Skipping Validation Dataset creation (df_val is empty or undefined).\")\n\nif 'df_test' in globals() and not df_test.empty:\n    print(\"\\nCreating Test Dataset...\")\n    test_dataset = CaptionClassificationDataset(\n        dataframe=df_test,\n        tokenizer=tokenizer,\n        max_len=MAX_LEN\n    )\n    print(f\"Test Dataset created with {len(test_dataset)} samples.\")\n    # Optional: Check a sample output from the test dataset\n    # sample = test_dataset[0]\n    # print(\"\\nSample from Test Dataset:\")\n    # print(f\"  Input Text: {sample['input_text']}\")\n    # print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n    # print(f\"  Attention Mask shape: {sample['attention_mask'].shape}\")\n    # print(f\"  Label: {sample['labels']}\")\nelse:\n    print(\"Skipping Test Dataset creation (df_test is empty or undefined).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:28.776173Z","iopub.execute_input":"2025-04-14T14:53:28.776426Z","iopub.status.idle":"2025-04-14T14:53:29.078549Z","shell.execute_reply.started":"2025-04-14T14:53:28.776409Z","shell.execute_reply":"2025-04-14T14:53:29.077724Z"}},"outputs":[{"name":"stdout","text":"\nInitializing BERT tokenizer: google-bert/bert-base-uncased\nTokenizer initialized.\n\nCreating Train Dataset...\nTrain Dataset created with 7436 samples.\n\nCreating Validation Dataset...\nValidation Dataset created with 1062 samples.\n\nCreating Test Dataset...\nTest Dataset created with 2126 samples.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# --- Part C: Caption Classifier Model Definition ---\n\n# Ensure BertForSequenceClassification is imported\nfrom transformers import BertForSequenceClassification\nimport torch.nn as nn\n\n# Compulsory Class Definition: CaptionClassifier\nclass CaptionClassifier(nn.Module):\n    \"\"\"\n    A classifier model based on a pre-trained BERT model.\n    This implementation uses Hugging Face's BertForSequenceClassification\n    for simplicity and standard practice.\n    \"\"\"\n    def __init__(self, bert_model_name, num_labels=2):\n        \"\"\"\n        Args:\n            bert_model_name (str): The name of the pre-trained BERT model\n                                   (e.g., 'google-bert/bert-base-uncased').\n            num_labels (int): The number of output classes (2 for binary: SmolVLM vs Custom).\n        \"\"\"\n        super(CaptionClassifier, self).__init__()\n        print(f\"Initializing CaptionClassifier with base model: {bert_model_name}\")\n        # Load the pre-trained BERT model with a sequence classification head\n        # The `num_labels` argument automatically configures the final linear layer\n        self.bert = BertForSequenceClassification.from_pretrained(\n            bert_model_name,\n            num_labels=num_labels\n        )\n        print(f\"Loaded {bert_model_name} with classification head for {num_labels} labels.\")\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        \"\"\"\n        Forward pass for the classifier.\n\n        Args:\n            input_ids (torch.Tensor): Tensor of input token IDs (batch_size, seq_length).\n            attention_mask (torch.Tensor): Tensor indicating which tokens to attend to (batch_size, seq_length).\n            labels (torch.Tensor, optional): Tensor of true labels (batch_size).\n                                             If provided, the model also returns the loss.\n\n        Returns:\n            transformers.modeling_outputs.SequenceClassifierOutput:\n                An object containing loss (if labels provided) and logits.\n                Access logits via output.logits.\n        \"\"\"\n        # Pass inputs directly to the underlying BertForSequenceClassification model\n        # It handles the CLS token processing and classification internally\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels # Pass labels to compute loss during training\n        )\n        return outputs\n\n# --- Model Initialization ---\n# Ensure BERT_MODEL_NAME is defined from the constants snippet\nif 'BERT_MODEL_NAME' not in globals(): raise NameError(\"BERT_MODEL_NAME not defined.\")\n# Ensure DEVICE is defined\nif 'DEVICE' not in globals(): raise NameError(\"DEVICE not defined.\")\n\nprint(\"\\nInstantiating the CaptionClassifier model...\")\n# Initialize the model with 2 output labels (SmolVLM vs Custom)\ntry:\n    model = CaptionClassifier(bert_model_name=BERT_MODEL_NAME, num_labels=2)\n    model.to(DEVICE) # Move the model to the GPU (or CPU if not available)\n    print(f\"CaptionClassifier model instantiated and moved to {DEVICE}.\")\n\n    # Optional: Print model structure summary\n    # print(\"\\nModel Structure:\")\n    # print(model)\n\nexcept Exception as e:\n    print(f\"ERROR: Failed to initialize CaptionClassifier model: {e}\")\n    model = None # Set model to None if initialization fails","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:29.079359Z","iopub.execute_input":"2025-04-14T14:53:29.079633Z","iopub.status.idle":"2025-04-14T14:53:29.861040Z","shell.execute_reply.started":"2025-04-14T14:53:29.079605Z","shell.execute_reply":"2025-04-14T14:53:29.860386Z"}},"outputs":[{"name":"stdout","text":"\nInstantiating the CaptionClassifier model...\nInitializing CaptionClassifier with base model: google-bert/bert-base-uncased\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Loaded google-bert/bert-base-uncased with classification head for 2 labels.\nCaptionClassifier model instantiated and moved to cuda.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- Part C: Training Setup and Function ---\n\nfrom torch.utils.data import DataLoader\nfrom transformers import get_linear_schedule_with_warmup # Ensure these are imported\nimport torch.nn as nn\nimport torch # Ensure torch is imported\n\n# --- Create DataLoaders ---\n# Ensure datasets (train_dataset, val_dataset) exist from the Dataset step\n# Ensure BATCH_SIZE is defined\nif 'BATCH_SIZE' not in globals(): raise NameError(\"BATCH_SIZE not defined.\")\n\ntrain_dataloader = None\nval_dataloader = None\n\nif 'train_dataset' in globals() and train_dataset is not None:\n    print(\"\\nCreating Training DataLoader...\")\n    train_dataloader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True, # Shuffle training data\n        num_workers=2\n    )\n    print(f\"Training DataLoader created with {len(train_dataloader)} batches.\")\nelse:\n    print(\"Skipping Training DataLoader creation (train_dataset not available).\")\n\n\nif 'val_dataset' in globals() and val_dataset is not None:\n    print(\"\\nCreating Validation DataLoader...\")\n    val_dataloader = DataLoader(\n        val_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False, # No need to shuffle validation data\n        num_workers=2\n    )\n    print(f\"Validation DataLoader created with {len(val_dataloader)} batches.\")\nelse:\n    print(\"Skipping Validation DataLoader creation (val_dataset not available).\")\n\n\n# --- Optimizer and Loss Function ---\n# Ensure the 'model' object (CaptionClassifier instance) exists and LEARNING_RATE is defined\nif 'model' in globals() and model is not None and 'LEARNING_RATE' in globals():\n    print(\"\\nSetting up optimizer and loss function...\")\n    # Use AdamW optimizer (standard for Transformers)\n    optimizer = AdamW(\n        model.parameters(),\n        lr=LEARNING_RATE,\n        eps=1e-8 # Epsilon value to prevent division by zero\n    )\n\n    # Use CrossEntropyLoss for classification\n    criterion = nn.CrossEntropyLoss().to(DEVICE) # Move loss function to device if needed (usually not)\n    print(\"Optimizer (AdamW) and Loss Function (CrossEntropyLoss) created.\")\n\n    # Optional: Learning Rate Scheduler\n    # Calculate total training steps for scheduler\n    if train_dataloader:\n        total_steps = len(train_dataloader) * EPOCHS # EPOCHS should be defined\n        # Create linear scheduler with warmup\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0, # Default: no warmup steps\n            num_training_steps=total_steps\n        )\n        print(f\"Learning rate scheduler created for {total_steps} total steps.\")\n    else:\n        scheduler = None # No scheduler if no training data\n        print(\"Skipping scheduler creation (no training dataloader).\")\n\nelse:\n    print(\"Skipping optimizer/loss setup (model is None or LEARNING_RATE not defined).\")\n    optimizer = None\n    criterion = None\n    scheduler = None\n\n\n# --- Compulsory Function: train_classifier ---\ndef train_classifier(model, dataloader, optimizer, criterion, device, epoch, scheduler=None):\n    \"\"\"\n    Performs one epoch of training for the caption classifier.\n\n    Args:\n        model (nn.Module): The CaptionClassifier model.\n        dataloader (DataLoader): DataLoader for the training data.\n        optimizer (Optimizer): The optimizer (e.g., AdamW).\n        criterion (Loss): The loss function (e.g., CrossEntropyLoss).\n        device (str): 'cuda' or 'cpu'.\n        epoch (int): Current epoch number (for logging).\n        scheduler (LRScheduler, optional): Learning rate scheduler.\n\n    Returns:\n        float: The average training loss for the epoch.\n    \"\"\"\n    if model is None or dataloader is None or optimizer is None or criterion is None:\n        print(\"Error in train_classifier: Missing model, dataloader, optimizer, or criterion.\")\n        return float('inf') # Return infinite loss to signal failure\n\n    print(f\"\\n--- Starting Training Epoch {epoch + 1} ---\")\n    model.train() # Set model to training mode\n\n    total_loss = 0\n    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} Train\", leave=False)\n\n    for batch in progress_bar:\n        # Move batch to device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels # Pass labels directly to BertForSequenceClassification\n        )\n\n        # BertForSequenceClassification directly returns loss when labels are provided\n        loss = outputs.loss\n\n        # Backward pass\n        loss.backward()\n\n        # Gradient clipping (optional but often helpful with Transformers)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update weights\n        optimizer.step()\n\n        # Update learning rate scheduler (if used)\n        if scheduler:\n            scheduler.step()\n\n        # Accumulate loss\n        total_loss += loss.item()\n\n        # Update progress bar description (optional)\n        progress_bar.set_postfix({'loss': loss.item()})\n\n    # Calculate average loss for the epoch\n    avg_train_loss = total_loss / len(dataloader)\n    print(f\"Epoch {epoch + 1} Average Training Loss: {avg_train_loss:.4f}\")\n\n    return avg_train_loss\n\n# --- Optional: Validation Function (Recommended) ---\ndef validate_classifier(model, dataloader, criterion, device, epoch):\n    \"\"\"Performs one epoch of validation.\"\"\"\n    if model is None or dataloader is None or criterion is None:\n        print(\"Error in validate_classifier: Missing model, dataloader, or criterion.\")\n        return float('inf'), 0.0 # Return infinite loss and 0 accuracy\n\n    print(f\"\\n--- Starting Validation Epoch {epoch + 1} ---\")\n    model.eval() # Set model to evaluation mode\n\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} Val\", leave=False)\n\n    with torch.no_grad(): # Disable gradient calculations\n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n\n            loss = outputs.loss\n            logits = outputs.logits\n\n            total_loss += loss.item()\n\n            # Calculate accuracy\n            predictions = torch.argmax(logits, dim=-1)\n            correct_predictions += torch.sum(predictions == labels).item()\n            total_predictions += labels.size(0)\n\n            progress_bar.set_postfix({'loss': loss.item()})\n\n    avg_val_loss = total_loss / len(dataloader)\n    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0\n    print(f\"Epoch {epoch + 1} Average Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n\n    return avg_val_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:29.861827Z","iopub.execute_input":"2025-04-14T14:53:29.862071Z","iopub.status.idle":"2025-04-14T14:53:29.878145Z","shell.execute_reply.started":"2025-04-14T14:53:29.862054Z","shell.execute_reply":"2025-04-14T14:53:29.877339Z"}},"outputs":[{"name":"stdout","text":"\nCreating Training DataLoader...\nTraining DataLoader created with 465 batches.\n\nCreating Validation DataLoader...\nValidation DataLoader created with 67 batches.\n\nSetting up optimizer and loss function...\nOptimizer (AdamW) and Loss Function (CrossEntropyLoss) created.\nLearning rate scheduler created for 1860 total steps.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# --- Part C: Evaluation Function ---\n\nfrom sklearn.metrics import precision_recall_fscore_support # Ensure this is imported\nimport torch # Ensure torch is imported\n\n# --- Create Test DataLoader ---\n# Ensure test_dataset exists from the Dataset step\n# Ensure BATCH_SIZE is defined\nif 'BATCH_SIZE' not in globals(): raise NameError(\"BATCH_SIZE not defined.\")\n\ntest_dataloader = None\nif 'test_dataset' in globals() and test_dataset is not None:\n    print(\"\\nCreating Test DataLoader...\")\n    test_dataloader = DataLoader(\n        test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False, # No shuffling for test set\n        num_workers=2\n    )\n    print(f\"Test DataLoader created with {len(test_dataloader)} batches.\")\nelse:\n    print(\"Skipping Test DataLoader creation (test_dataset not available).\")\n\n\n# --- Compulsory Function: evaluate_classifier ---\ndef evaluate_classifier(model, dataloader, device):\n    \"\"\"\n    Evaluates the classifier on a given dataset (typically the test set).\n\n    Args:\n        model (nn.Module): The trained CaptionClassifier model.\n        dataloader (DataLoader): DataLoader for the evaluation data.\n        device (str): 'cuda' or 'cpu'.\n\n    Returns:\n        dict: A dictionary containing macro precision, recall, and F1-score.\n              Returns None if evaluation cannot be performed.\n    \"\"\"\n    if model is None or dataloader is None:\n        print(\"Error in evaluate_classifier: Missing model or dataloader.\")\n        return None # Cannot evaluate\n\n    print(\"\\n--- Starting Final Evaluation on Test Set ---\")\n    model.eval() # Set model to evaluation mode\n\n    all_preds = []\n    all_labels = []\n\n    progress_bar = tqdm(dataloader, desc=\"Evaluating Test Set\", leave=False)\n\n    with torch.no_grad(): # Disable gradient calculations\n        for batch in progress_bar:\n            # Move batch to device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            # Forward pass - only need logits for prediction\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n                # Do NOT pass labels here for evaluation\n            )\n            logits = outputs.logits\n\n            # Get predictions (index of the max logit)\n            predictions = torch.argmax(logits, dim=-1)\n\n            # Move predictions and labels to CPU and store as numpy arrays or lists\n            all_preds.extend(predictions.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Ensure predictions were made\n    if not all_labels or not all_preds:\n        print(\"Warning: No labels or predictions collected during evaluation. Cannot calculate metrics.\")\n        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0} # Return zero scores\n\n\n    # Calculate metrics using sklearn\n    # Use average='macro' as required by the assignment\n    # Set zero_division=0 to handle cases where a class might have 0 predictions/labels in a batch or split\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels,\n        all_preds,\n        average='macro',\n        zero_division=0\n    )\n\n    print(\"\\n--- Evaluation Metrics (Test Set) ---\")\n    print(f\"Macro Precision: {precision:.4f}\")\n    print(f\"Macro Recall:    {recall:.4f}\")\n    print(f\"Macro F1-Score:  {f1:.4f}\")\n\n    # Return results in a dictionary\n    return {\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:29.879699Z","iopub.execute_input":"2025-04-14T14:53:29.879940Z","iopub.status.idle":"2025-04-14T14:53:29.896976Z","shell.execute_reply.started":"2025-04-14T14:53:29.879924Z","shell.execute_reply":"2025-04-14T14:53:29.896249Z"}},"outputs":[{"name":"stdout","text":"\nCreating Test DataLoader...\nTest DataLoader created with 133 batches.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --- Part C: Main Execution Script ---\n\nimport torch\nimport numpy as np # For setting random seed\nimport random # For setting random seed\nimport time # For timing execution\n\n# --- Set Random Seeds for Reproducibility ---\n# Ensure RANDOM_SEED is defined from the Constants cell\nif 'RANDOM_SEED' not in globals():\n    RANDOM_SEED = 42 # Default seed if not defined\n    print(f\"Warning: RANDOM_SEED not defined, using default: {RANDOM_SEED}\")\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(RANDOM_SEED)\n    # Potentially add these for further determinism, but can impact performance\n    # torch.backends.cudnn.deterministic = True\n    # torch.backends.cudnn.benchmark = False\nprint(f\"Set random seeds to {RANDOM_SEED}\")\n\n\n# --- Check Prerequisites ---\n# Verify necessary components are ready before starting training\nprint(\"\\nVerifying prerequisites for training...\")\n# Check if model, optimizer, criterion, dataloaders, etc., exist and are not None\ncomponents_ready = (\n    'model' in globals() and model is not None and\n    'optimizer' in globals() and optimizer is not None and\n    'criterion' in globals() and criterion is not None and\n    'train_dataloader' in globals() and train_dataloader is not None and\n    'val_dataloader' in globals() and val_dataloader is not None and\n    'test_dataloader' in globals() and test_dataloader is not None and\n    'EPOCHS' in globals() and\n    'DEVICE' in globals()\n)\n\nif not components_ready:\n    print(\"ERROR: Not all necessary components (model, optimizer, criterion, dataloaders, EPOCHS, DEVICE) are initialized.\")\n    print(\"       Please ensure previous cells ran successfully. Aborting training.\")\n    # You might want to raise an error here or exit if in a script\n    # raise RuntimeError(\"Prerequisites for training not met.\")\nelse:\n    print(\"Prerequisites met. Starting training loop...\")\n    start_time = time.time()\n\n    # --- Training Loop ---\n    best_val_accuracy = -1.0 # Keep track of best validation accuracy\n    best_epoch = -1\n    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []} # Store metrics per epoch\n\n    for epoch in range(EPOCHS):\n        # --- Training Step ---\n        avg_train_loss = train_classifier(\n            model=model,\n            dataloader=train_dataloader,\n            optimizer=optimizer,\n            criterion=criterion,\n            device=DEVICE,\n            epoch=epoch,\n            scheduler=scheduler if 'scheduler' in globals() else None # Pass scheduler if defined\n        )\n        history['train_loss'].append(avg_train_loss)\n\n        # --- Validation Step ---\n        # Use the optional validation function defined earlier\n        avg_val_loss, val_accuracy = validate_classifier(\n            model=model,\n            dataloader=val_dataloader,\n            criterion=criterion, # Loss function needed for validation loss calculation\n            device=DEVICE,\n            epoch=epoch\n        )\n        history['val_loss'].append(avg_val_loss)\n        history['val_accuracy'].append(val_accuracy)\n\n        # Optional: Save the model checkpoint if validation accuracy improves\n        if val_accuracy > best_val_accuracy:\n            print(f\"Validation accuracy improved from {best_val_accuracy:.4f} to {val_accuracy:.4f}. Saving model...\")\n            best_val_accuracy = val_accuracy\n            best_epoch = epoch\n            # Define a path to save the best model\n            output_dir = \"/kaggle/working/\" # Or your Drive path\n            os.makedirs(output_dir, exist_ok=True)\n            best_model_path = os.path.join(output_dir, \"best_caption_classifier_model.pth\")\n            try:\n                torch.save(model.state_dict(), best_model_path)\n                print(f\"Best model saved to {best_model_path}\")\n            except Exception as e:\n                print(f\"Error saving model checkpoint: {e}\")\n\n        print(\"-\" * 30) # Separator between epochs\n\n    end_time = time.time()\n    training_time = end_time - start_time\n    print(f\"\\n--- Training Complete ---\")\n    print(f\"Total Training Time: {training_time:.2f} seconds\")\n    print(f\"Best Validation Accuracy: {best_val_accuracy:.4f} at Epoch {best_epoch + 1}\")\n\n    # --- Final Evaluation on Test Set ---\n    print(\"\\n--- Evaluating on Test Set using the *last* epoch model ---\")\n    # Note: For best results, you might load the *best* saved checkpoint based on validation accuracy\n    # Example:\n    # if os.path.exists(best_model_path):\n    #     print(f\"Loading best model from {best_model_path} for final evaluation...\")\n    #     model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\n    # else:\n    #     print(\"Warning: Best model checkpoint not found. Evaluating with the model from the last epoch.\")\n\n    # Call the evaluation function\n    test_results = evaluate_classifier(\n        model=model,\n        dataloader=test_dataloader,\n        device=DEVICE\n    )\n\n    if test_results:\n        print(\"\\n--- Final Test Set Performance ---\")\n        print(f\"  Macro Precision: {test_results.get('precision', 0.0):.4f}\")\n        print(f\"  Macro Recall:    {test_results.get('recall', 0.0):.4f}\")\n        print(f\"  Macro F1-Score:  {test_results.get('f1', 0.0):.4f}\")\n    else:\n        print(\"\\nTest evaluation could not be performed.\")\n\n# --- End of Part C Execution ---","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T14:53:29.897608Z","iopub.execute_input":"2025-04-14T14:53:29.897815Z","iopub.status.idle":"2025-04-14T15:00:48.444409Z","shell.execute_reply.started":"2025-04-14T14:53:29.897799Z","shell.execute_reply":"2025-04-14T15:00:48.443335Z"}},"outputs":[{"name":"stdout","text":"Set random seeds to 42\n\nVerifying prerequisites for training...\nPrerequisites met. Starting training loop...\n\n--- Starting Training Epoch 1 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1 Train:   0%|          | 0/465 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1 Average Training Loss: 0.0857\n\n--- Starting Validation Epoch 1 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1 Val:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1 Average Validation Loss: 0.0367, Accuracy: 0.9821\nValidation accuracy improved from -1.0000 to 0.9821. Saving model...\nBest model saved to /kaggle/working/best_caption_classifier_model.pth\n------------------------------\n\n--- Starting Training Epoch 2 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2 Train:   0%|          | 0/465 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2 Average Training Loss: 0.0350\n\n--- Starting Validation Epoch 2 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2 Val:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2 Average Validation Loss: 0.0445, Accuracy: 0.9831\nValidation accuracy improved from 0.9821 to 0.9831. Saving model...\nBest model saved to /kaggle/working/best_caption_classifier_model.pth\n------------------------------\n\n--- Starting Training Epoch 3 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3 Train:   0%|          | 0/465 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3 Average Training Loss: 0.0300\n\n--- Starting Validation Epoch 3 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3 Val:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3 Average Validation Loss: 0.0645, Accuracy: 0.9765\n------------------------------\n\n--- Starting Training Epoch 4 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4 Train:   0%|          | 0/465 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4 Average Training Loss: 0.0247\n\n--- Starting Validation Epoch 4 ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4 Val:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4 Average Validation Loss: 0.0878, Accuracy: 0.9755\n------------------------------\n\n--- Training Complete ---\nTotal Training Time: 430.93 seconds\nBest Validation Accuracy: 0.9831 at Epoch 2\n\n--- Evaluating on Test Set using the *last* epoch model ---\n\n--- Starting Final Evaluation on Test Set ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating Test Set:   0%|          | 0/133 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluation Metrics (Test Set) ---\nMacro Precision: 0.9770\nMacro Recall:    0.9770\nMacro F1-Score:  0.9770\n\n--- Final Test Set Performance ---\n  Macro Precision: 0.9770\n  Macro Recall:    0.9770\n  Macro F1-Score:  0.9770\n","output_type":"stream"}],"execution_count":9}]}